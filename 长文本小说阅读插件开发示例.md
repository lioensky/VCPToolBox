@同步异步开发手册

今天我们来开发一个异步插件或者同步委托进程插件，“长小说阅读器”。

首先，面对几千万字甚至几亿字，动则几百几千章节的长小说，让有效上下文顶天200k的llm直接阅读是几乎不可能做到的。因此我们今天来设计一个这样的插件，来设计一个超长小说阅读器，帮助ai在有限上下文里也能阅读超长小说。

一.设计思路，将任意txt小说转化为数据库索引(json即可，后续考虑sqlite以利用wal事务功能)，如果是epub则可以更容易的塑造索引，论文pdf图表太多了可以用MinerUapi解析这里应该留一个端口。但我们这里首先以txt为例，假定有一个20mb的txt文件，里面是整个小说的完整文本。
二.指令集设计，为了让ai可以理解整部小说的完整内容，我们需要如下流程和如下插件command指令集————

1.获取txt内容。
输入文件url字段，headerlines字段，让ai可以只阅读小说开头的固定多少行内容，比如100行，500行之类的。这样，ai可以读完序章部分，并理解 标题 的文本样式。
2.创建json索引。
输入文件url字段，标题匹配正则（这部分必须由主agent输入），两个字段内容，从而快速构建小说的章节索引。
3.阅读json章节索引。
让ai检查章节索引是否构建成功，同时也是阅读所有标题，让ai对小说了解一个大概。

epub文件可以执行类似的操作但可以相对简化。epub相关开发后续再议，预留接口即可。

三.异步获取小说剧情完整内容。
1.创建子agent用于并发总结小说剧情。@Agent提示词大师小绝 来创建子agent用户总结单章节剧情，并留下剧情脉络索引。
在插件.env文件里提供 子agent的url，key，最大单次阅读token上限，并发上限，retry循环回退上限。

2.这里可以设计2套命令集。并发阅读和轮式精读。
无论哪个指令首先要判断小说文件json/sql索引是否已创建（标题索引流程），否则抛出报错。
实现段落级chunk来避免一章太长，小模型一次读不完的chunk切割器。

并发阅读：字面意思，按照并发上限让子agent阅读所有的章节逐一总结剧情和剧情索引，归档入库。  解析方式@Agent提示词大师小绝 来完成。

轮式精度：对于剧情复杂，人物关系密集的小说，建议使用此模式进行阅读————
按章节顺序进行总结剧情，每次总结一个新章节剧情时，除了发给子agent章节文本，还要带上之前的x章剧情总结部分。并通过提示词引导它只输出新章节的剧情总结。此处的x由主agent调用插件发送异步命令轮式精度时引入，默认1。

四.插件回调和阅读。
占位符和回调服务器参考异步开发手册。
让子agent阅读的指令集————
1.获取所有标题和章节信息。
2.阅读 a-b 章节间所有的总结和索引。
3.允许使用bm25算法，在特定章节原文发起剧情检索，语法类似codersearch。
4.考虑实现“总结的总结”功能（例如1-50章说了什么），可以留到后续开发。

注意构建 章节列表——章节总结——原文分章间的持久化json索引关系。
至此，插件功能基本实践完毕。









